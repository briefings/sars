{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes in progress ...\n",
    "\n",
    "<dl>\n",
    "    <dt><b>Aim</b></dt>\n",
    "  <dd>Determine the degree of dispersion, per day, amongst a state's delta curves.</dd>\n",
    "  <dt><b>Why?</b></dt>\n",
    "    <dd>In the case of <i>positive rate delta curves</i>, as the dispersion increases from zero, the more likely an impending outbreak [mathematical proof].  In the case of <i>hospitalization rate delta curves</i>, as the dispersion increases from zero, it is quite probable that hospitalisations will increase rapidly [contingency planning alert?] </dd>\n",
    "</dl>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "child = os.getcwd()\n",
    "parent = str(pathlib.Path(child).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(child, 'warehouse')\n",
    "warehouse = os.path.join(root, 'dispersions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Appending Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:J:\\library\\projects\\sars\\fundamentals\\atlantic\\notebooks\\warehouse\n"
     ]
    }
   ],
   "source": [
    "logger.info(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:J:\\library\\projects\\sars\\fundamentals\\atlantic\\notebooks\\warehouse\\dispersions\n"
     ]
    }
   ],
   "source": [
    "logger.info(warehouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atlantic.base.directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Set-up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = atlantic.base.directories.Directories()\n",
    "directories.cleanup(listof=[warehouse])\n",
    "directories.create(listof=[warehouse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "datauri = os.path.join(root, 'trends', 'percentages.csv')\n",
    "\n",
    "parse_dates = ['datetimeobject']\n",
    "percentages = pd.read_csv(filepath_or_buffer=datauri, header=0, encoding='utf-8', parse_dates=parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195468 entries, 0 to 195467\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   datetimeobject         195468 non-null  datetime64[ns]\n",
      " 1   STUSPS                 195468 non-null  object        \n",
      " 2   period                 195468 non-null  object        \n",
      " 3   deathRateDelta         195468 non-null  float64       \n",
      " 4   deathRate              195468 non-null  float64       \n",
      " 5   positiveRateDelta      195468 non-null  float64       \n",
      " 6   positiveRate           195468 non-null  float64       \n",
      " 7   testRateDelta          195468 non-null  float64       \n",
      " 8   testRate               195468 non-null  float64       \n",
      " 9   icuRateDelta           195468 non-null  float64       \n",
      " 10  icuRate                195468 non-null  float64       \n",
      " 11  hospitalizedRateDelta  195468 non-null  float64       \n",
      " 12  hospitalizedRate       195468 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(10), object(2)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "logger.info(percentages.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = ['positiveRateDelta', 'deathRateDelta', 'hospitalizedRateDelta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Baseline table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(data: pd.DataFrame, section: str):\n",
    "    \n",
    "    structure = pd.pivot_table(data, index=['datetimeobject', 'STUSPS'], columns=['period'], values=[section])\n",
    "    structure.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "    periodfields = structure.columns\n",
    "\n",
    "    structure.loc[:, 'range'] = structure[periodfields].max(axis=1) - structure[periodfields].min(axis=1)\n",
    "    structure.loc[:, 'midpoint'] = 0.5*structure['range'] + structure[periodfields].min(axis=1)\n",
    "    structure.loc[:, 'median'] = structure[periodfields].median(axis=1)\n",
    "\n",
    "    structure.reset_index(drop=False, inplace=True)    \n",
    "    matrix = structure[['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median']].values\n",
    "    \n",
    "    return pd.DataFrame(data=matrix, columns=['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(data: pd.DataFrame):\n",
    "    \n",
    "    blob = data.copy()\n",
    "    \n",
    "    scores = blob[['range', 'midpoint']].apply(lambda x: x['midpoint'] * np.log(x['range']) if x['range'] > 0 else 0, axis=1)\n",
    "    \n",
    "    return pd.concat([blob, scores.rename('score')], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest(data: pd.DataFrame):\n",
    "    \n",
    "    blob = data.copy()\n",
    "    \n",
    "    condition = blob['datetimeobject'] == blob['datetimeobject'].max()\n",
    "    \n",
    "    return blob[condition].sort_values(by='rank')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "positiveRateDelta\n",
      "\n",
      "INFO:__main__:\n",
      "  datetimeobject STUSPS range midpoint median  score  rank\n",
      "0     2020-02-13     AK     0        0      0    0.0   1.0\n",
      "1     2020-02-13     AL     0        0      0    0.0   1.0\n",
      "2     2020-02-13     AR     0        0      0    0.0   1.0\n",
      "3     2020-02-13     AZ     0        0      0    0.0   1.0\n",
      "4     2020-02-13     CA     0        0      0    0.0   1.0\n",
      "\n",
      "INFO:__main__:\n",
      "      datetimeobject STUSPS    range midpoint   median       score  rank\n",
      "12506     2020-10-10     MT   74.903  46.0861  49.6407  198.916716   1.0\n",
      "12531     2020-10-10     WY  51.9281  31.0825  32.3451  122.771531   2.0\n",
      "12522     2020-10-10     SD  48.8011  30.2163  29.7386  117.473580   3.0\n",
      "12508     2020-10-10     ND  49.6437  29.7226  28.4887  116.062770   4.0\n",
      "12529     2020-10-10     WI  46.7398  27.4745  27.0449  105.628255   5.0\n",
      "\n",
      "INFO:__main__:\n",
      "deathRateDelta\n",
      "\n",
      "INFO:__main__:\n",
      "  datetimeobject STUSPS range midpoint median  score  rank\n",
      "0     2020-02-13     AK     0        0      0    0.0   1.0\n",
      "1     2020-02-13     AL     0        0      0    0.0   1.0\n",
      "2     2020-02-13     AR     0        0      0    0.0   1.0\n",
      "3     2020-02-13     AZ     0        0      0    0.0   1.0\n",
      "4     2020-02-13     CA     0        0      0    0.0   1.0\n",
      "\n",
      "INFO:__main__:\n",
      "      datetimeobject STUSPS    range midpoint   median       score  rank\n",
      "12508     2020-10-10     ND  64.7887  32.3944       50  135.121168   1.0\n",
      "12491     2020-10-10     HI  53.2997  28.4903  26.7176  113.275611   2.0\n",
      "12522     2020-10-10     SD  39.2974  24.7958  31.1927   91.029122   3.0\n",
      "12506     2020-10-10     MT  37.0593   24.621  20.8092   88.943948   4.0\n",
      "12504     2020-10-10     MO  28.8518  21.6415  17.4018   72.762475   5.0\n",
      "\n",
      "INFO:__main__:\n",
      "hospitalizedRateDelta\n",
      "\n",
      "INFO:__main__:\n",
      "  datetimeobject STUSPS range midpoint median  score  rank\n",
      "0     2020-02-13     AK     0        0      0    0.0   1.0\n",
      "1     2020-02-13     AL     0        0      0    0.0   1.0\n",
      "2     2020-02-13     AR     0        0      0    0.0   1.0\n",
      "3     2020-02-13     AZ     0        0      0    0.0   1.0\n",
      "4     2020-02-13     CA     0        0      0    0.0   1.0\n",
      "\n",
      "INFO:__main__:\n",
      "      datetimeobject STUSPS    range midpoint   median       score  rank\n",
      "12506     2020-10-10     MT  55.4642  31.7274   28.821  127.408813   1.0\n",
      "12508     2020-10-10     ND  46.1107  27.5829  30.3067  105.671464   2.0\n",
      "12522     2020-10-10     SD  40.2667  26.6564  24.1684   98.509277   3.0\n",
      "12531     2020-10-10     WY  31.3884  18.8891  23.2824   65.100184   4.0\n",
      "12491     2020-10-10     HI  31.0911  17.4471   13.591   59.964449   5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for section in sections:\n",
    "    \n",
    "    # A dta set w.r.t. a measure\n",
    "    example = percentages[['datetimeobject', 'STUSPS', 'period', section]]\n",
    "    logger.info('\\n{}\\n'.format(section))\n",
    "    \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median'] \n",
    "    data = baseline(data=example, section=section)\n",
    "        \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median', 'score']\n",
    "    data = scores(data=data)\n",
    "            \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median', 'score', 'rank']\n",
    "    ranks = data[['datetimeobject', 'score']].groupby(by='datetimeobject').rank(method='min', ascending=False).score\n",
    "    data = pd.concat([data, ranks.rename('rank')], axis=1)    \n",
    "    data.to_csv(path_or_buf=os.path.join(warehouse, section + 'Dispersion.csv'), header=True, encoding='utf-8', index=False)\n",
    "    logger.info('\\n{}\\n'.format(data.head()))\n",
    "    \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median', 'score', 'rank']\n",
    "    inbrief = latest(data=data)\n",
    "    inbrief.to_csv(path_or_buf=os.path.join(warehouse, section + 'DispersionLatest.csv'), header=True, encoding='utf-8', index=False)\n",
    "    logger.info('\\n{}\\n'.format(inbrief.head()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
