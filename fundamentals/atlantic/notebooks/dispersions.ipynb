{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes in progress ...\n",
    "\n",
    "<dl>\n",
    "    <dt><b>Aim</b></dt>\n",
    "  <dd>Determine the degree of dispersion, per day, amongst a state's delta curves.</dd>\n",
    "  <dt><b>Why?</b></dt>\n",
    "    <dd>In the case of <i>positive rate delta curves</i>, as the dispersion increases from zero, the more likely an impending outbreak [mathematical proof].  In the case of <i>hospitalization rate delta curves</i>, as the dispersion increases from zero, it is quite probable that hospitalisations will increase rapidly [contingency planning alert?] </dd>\n",
    "</dl>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "child = os.getcwd()\n",
    "parent = str(pathlib.Path(child).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(child, 'warehouse')\n",
    "warehouse = os.path.join(root, 'dispersions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Appending Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:J:\\library\\projects\\sars\\fundamentals\\atlantic\\notebooks\\warehouse\n"
     ]
    }
   ],
   "source": [
    "logger.info(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:J:\\library\\projects\\sars\\fundamentals\\atlantic\\notebooks\\warehouse\\dispersions\n"
     ]
    }
   ],
   "source": [
    "logger.info(warehouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atlantic.base.directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Set-up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = atlantic.base.directories.Directories()\n",
    "directories.cleanup(listof=[warehouse])\n",
    "directories.create(listof=[warehouse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datauri = os.path.join(root, 'trends', 'percentages.csv')\n",
    "\n",
    "parse_dates = ['datetimeobject']\n",
    "percentages = pd.read_csv(filepath_or_buffer=datauri, header=0, encoding='utf-8', parse_dates=parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 219648 entries, 0 to 219647\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   datetimeobject         219648 non-null  datetime64[ns]\n",
      " 1   STUSPS                 219648 non-null  object        \n",
      " 2   period                 219648 non-null  object        \n",
      " 3   deathRateDelta         219648 non-null  float64       \n",
      " 4   deathRate              219648 non-null  float64       \n",
      " 5   positiveRateDelta      219648 non-null  float64       \n",
      " 6   positiveRate           219648 non-null  float64       \n",
      " 7   testRateDelta          219648 non-null  float64       \n",
      " 8   testRate               219648 non-null  float64       \n",
      " 9   icuRateDelta           219648 non-null  float64       \n",
      " 10  icuRate                219648 non-null  float64       \n",
      " 11  hospitalizedRateDelta  219648 non-null  float64       \n",
      " 12  hospitalizedRate       219648 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(10), object(2)\n",
      "memory usage: 21.8+ MB\n"
     ]
    }
   ],
   "source": [
    "logger.info(percentages.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = ['positiveRateDelta', 'deathRateDelta', 'hospitalizedRateDelta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Baseline table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(data: pd.DataFrame, section: str):\n",
    "    \n",
    "    structure = pd.pivot_table(data, index=['datetimeobject', 'STUSPS'], columns=['period'], values=[section])\n",
    "    structure.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "    periodfields = structure.columns\n",
    "\n",
    "    structure.loc[:, 'range'] = structure[periodfields].max(axis=1) - structure[periodfields].min(axis=1)\n",
    "    structure.loc[:, 'midpoint'] = 0.5*structure['range'] + structure[periodfields].min(axis=1)\n",
    "    structure.loc[:, 'median'] = structure[periodfields].median(axis=1)\n",
    "\n",
    "    structure.reset_index(drop=False, inplace=True)    \n",
    "    matrix = structure[['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median']].values\n",
    "    \n",
    "    return pd.DataFrame(data=matrix, columns=['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(data: pd.DataFrame):\n",
    "    \n",
    "    blob = data.copy()\n",
    "    \n",
    "    scores = blob[['range', 'midpoint']].apply(lambda x: x['midpoint'] * np.log(x['range']) if x['range'] > 0 else 0, axis=1)\n",
    "    \n",
    "    return pd.concat([blob, scores.rename('score')], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest(data: pd.DataFrame):\n",
    "    \n",
    "    blob = data.copy()\n",
    "    \n",
    "    condition = blob['datetimeobject'] == blob['datetimeobject'].max()\n",
    "    \n",
    "    return blob[condition].sort_values(by='rank')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "positiveRateDelta\n",
      "\n",
      "INFO:__main__:\n",
      "  datetimeobject STUSPS range midpoint median  score  rank\n",
      "0     2020-02-13     AK     0        0      0    0.0   1.0\n",
      "1     2020-02-13     AL     0        0      0    0.0   1.0\n",
      "2     2020-02-13     AR     0        0      0    0.0   1.0\n",
      "3     2020-02-13     AZ     0        0      0    0.0   1.0\n",
      "4     2020-02-13     CA     0        0      0    0.0   1.0\n",
      "\n",
      "INFO:__main__:\n",
      "      datetimeobject STUSPS    range midpoint   median       score  rank\n",
      "14143     2020-11-10     WY  95.4976    58.91  58.4225  268.576584   1.0\n",
      "14118     2020-11-10     MT  72.2244   39.822  37.3256  170.429163   2.0\n",
      "14120     2020-11-10     ND  68.8813  38.1917  41.1833  161.641782   3.0\n",
      "14092     2020-11-10     AK  65.4005  37.7744  37.4596  157.916953   4.0\n",
      "14134     2020-11-10     SD  65.9632  36.4651  36.5095  152.755960   5.0\n",
      "\n",
      "INFO:__main__:\n",
      "deathRateDelta\n",
      "\n",
      "INFO:__main__:\n",
      "  datetimeobject STUSPS range midpoint median  score  rank\n",
      "0     2020-02-13     AK     0        0      0    0.0   1.0\n",
      "1     2020-02-13     AL     0        0      0    0.0   1.0\n",
      "2     2020-02-13     AR     0        0      0    0.0   1.0\n",
      "3     2020-02-13     AZ     0        0      0    0.0   1.0\n",
      "4     2020-02-13     CA     0        0      0    0.0   1.0\n",
      "\n",
      "INFO:__main__:\n",
      "      datetimeobject STUSPS    range midpoint   median       score  rank\n",
      "14143     2020-11-10     WY  111.404  67.1053  64.9351  316.277763   1.0\n",
      "14118     2020-11-10     MT  90.3855  46.5085  42.1538  209.478238   2.0\n",
      "14134     2020-11-10     SD  66.4364  33.9645   40.625  142.523219   3.0\n",
      "14120     2020-11-10     ND  56.7809  31.9321  31.4815  128.980242   4.0\n",
      "14141     2020-11-10     WI  49.7316  28.6283  27.7406  111.840598   5.0\n",
      "\n",
      "INFO:__main__:\n",
      "hospitalizedRateDelta\n",
      "\n",
      "INFO:__main__:\n",
      "  datetimeobject STUSPS range midpoint median  score  rank\n",
      "0     2020-02-13     AK     0        0      0    0.0   1.0\n",
      "1     2020-02-13     AL     0        0      0    0.0   1.0\n",
      "2     2020-02-13     AR     0        0      0    0.0   1.0\n",
      "3     2020-02-13     AZ     0        0      0    0.0   1.0\n",
      "4     2020-02-13     CA     0        0      0    0.0   1.0\n",
      "\n",
      "INFO:__main__:\n",
      "      datetimeobject STUSPS    range midpoint   median       score  rank\n",
      "14123     2020-11-10     NJ  58.0193  29.4091  2.58237  119.423977   1.0\n",
      "14134     2020-11-10     SD  49.7818  27.8118  28.7623  108.678708   2.0\n",
      "14143     2020-11-10     WY  41.5744  28.1139  28.7411  104.794165   3.0\n",
      "14120     2020-11-10     ND   49.105  25.8816  25.4773  100.781900   4.0\n",
      "14118     2020-11-10     MT   45.805  25.1367  16.3328   96.132744   5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for section in sections:\n",
    "    \n",
    "    # A dta set w.r.t. a measure\n",
    "    example = percentages[['datetimeobject', 'STUSPS', 'period', section]]\n",
    "    logger.info('\\n{}\\n'.format(section))\n",
    "    \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median'] \n",
    "    data = baseline(data=example, section=section)\n",
    "        \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median', 'score']\n",
    "    data = scores(data=data)\n",
    "            \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median', 'score', 'rank']\n",
    "    ranks = data[['datetimeobject', 'score']].groupby(by='datetimeobject').rank(method='min', ascending=False).score\n",
    "    data = pd.concat([data, ranks.rename('rank')], axis=1)    \n",
    "    data.to_csv(path_or_buf=os.path.join(warehouse, section + 'Dispersion.csv'), header=True, encoding='utf-8', index=False)\n",
    "    logger.info('\\n{}\\n'.format(data.head()))\n",
    "    \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median', 'score', 'rank']\n",
    "    inbrief = latest(data=data)\n",
    "    inbrief.to_csv(path_or_buf=os.path.join(warehouse, section + 'DispersionLatest.csv'), header=True, encoding='utf-8', index=False)\n",
    "    logger.info('\\n{}\\n'.format(inbrief.head()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
