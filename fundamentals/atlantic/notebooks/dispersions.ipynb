{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes in progress ...\n",
    "\n",
    "<dl>\n",
    "    <dt><b>Aim</b></dt>\n",
    "  <dd>Determine the degree of dispersion, per day, amongst a state's delta curves.</dd>\n",
    "  <dt><b>Why?</b></dt>\n",
    "    <dd>In the case of <i>positive rate delta curves</i>, as the dispersion increases from zero, the more likely an impending outbreak [mathematical proof].  In the case of <i>hospitalization rate delta curves</i>, as the dispersion increases from zero, it is quite probable that hospitalisations will increase rapidly [contingency planning alert?] </dd>\n",
    "</dl>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "child = os.getcwd()\n",
    "parent = str(pathlib.Path(child).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(child, 'warehouse')\n",
    "warehouse = os.path.join(root, 'dispersions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Appending Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:J:\\library\\projects\\sars\\fundamentals\\atlantic\\notebooks\\warehouse\n"
     ]
    }
   ],
   "source": [
    "logger.info(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:J:\\library\\projects\\sars\\fundamentals\\atlantic\\notebooks\\warehouse\\dispersions\n"
     ]
    }
   ],
   "source": [
    "logger.info(warehouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atlantic.base.directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Set-up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = atlantic.base.directories.Directories()\n",
    "directories.cleanup(listof=[warehouse])\n",
    "directories.create(listof=[warehouse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datauri = os.path.join(root, 'trends', 'percentages.csv')\n",
    "\n",
    "parse_dates = ['datetimeobject']\n",
    "percentages = pd.read_csv(filepath_or_buffer=datauri, header=0, encoding='utf-8', parse_dates=parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 222768 entries, 0 to 222767\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   datetimeobject         222768 non-null  datetime64[ns]\n",
      " 1   STUSPS                 222768 non-null  object        \n",
      " 2   period                 222768 non-null  object        \n",
      " 3   deathRateDelta         222768 non-null  float64       \n",
      " 4   deathRate              222768 non-null  float64       \n",
      " 5   positiveRateDelta      222768 non-null  float64       \n",
      " 6   positiveRate           222768 non-null  float64       \n",
      " 7   testRateDelta          222768 non-null  float64       \n",
      " 8   testRate               222768 non-null  float64       \n",
      " 9   icuRateDelta           222768 non-null  float64       \n",
      " 10  icuRate                222768 non-null  float64       \n",
      " 11  hospitalizedRateDelta  222768 non-null  float64       \n",
      " 12  hospitalizedRate       222768 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(10), object(2)\n",
      "memory usage: 22.1+ MB\n"
     ]
    }
   ],
   "source": [
    "logger.info(percentages.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = ['positiveRateDelta', 'deathRateDelta', 'hospitalizedRateDelta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Baseline table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(data: pd.DataFrame, section: str):\n",
    "    \n",
    "    structure = pd.pivot_table(data, index=['datetimeobject', 'STUSPS'], columns=['period'], values=[section])\n",
    "    structure.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "    periodfields = structure.columns\n",
    "\n",
    "    structure.loc[:, 'range'] = structure[periodfields].max(axis=1) - structure[periodfields].min(axis=1)\n",
    "    structure.loc[:, 'midpoint'] = 0.5*structure['range'] + structure[periodfields].min(axis=1)\n",
    "    structure.loc[:, 'median'] = structure[periodfields].median(axis=1)\n",
    "\n",
    "    structure.reset_index(drop=False, inplace=True)    \n",
    "    matrix = structure[['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median']].values\n",
    "    \n",
    "    return pd.DataFrame(data=matrix, columns=['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(data: pd.DataFrame):\n",
    "    \n",
    "    blob = data.copy()\n",
    "    \n",
    "    scores = blob[['range', 'midpoint']].apply(lambda x: x['midpoint'] * np.log(x['range']) if x['range'] > 0 else 0, axis=1)\n",
    "    \n",
    "    return pd.concat([blob, scores.rename('score')], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest(data: pd.DataFrame):\n",
    "    \n",
    "    blob = data.copy()\n",
    "    \n",
    "    condition = blob['datetimeobject'] == blob['datetimeobject'].max()\n",
    "    \n",
    "    return blob[condition].sort_values(by='rank')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "positiveRateDelta\n",
      "\n",
      "INFO:__main__:\n",
      "  datetimeobject STUSPS range midpoint median  score  rank\n",
      "0     2020-02-13     AK     0        0      0    0.0   1.0\n",
      "1     2020-02-13     AL     0        0      0    0.0   1.0\n",
      "2     2020-02-13     AR     0        0      0    0.0   1.0\n",
      "3     2020-02-13     AZ     0        0      0    0.0   1.0\n",
      "4     2020-02-13     CA     0        0      0    0.0   1.0\n",
      "\n",
      "INFO:__main__:\n",
      "      datetimeobject STUSPS    range midpoint   median       score  rank\n",
      "14351     2020-11-14     WY  100.655  57.1736  59.4476  263.667561   1.0\n",
      "14328     2020-11-14     ND  68.6897   40.596  39.5822  171.704889   2.0\n",
      "14326     2020-11-14     MT  66.5004  39.8849  36.9936  167.405343   3.0\n",
      "14342     2020-11-14     SD  66.8144  39.1158  35.6225  164.361278   4.0\n",
      "14305     2020-11-14     CO   62.561  39.4517  43.4914  163.177868   5.0\n",
      "\n",
      "INFO:__main__:\n",
      "deathRateDelta\n",
      "\n",
      "INFO:__main__:\n",
      "  datetimeobject STUSPS range midpoint median  score  rank\n",
      "0     2020-02-13     AK     0        0      0    0.0   1.0\n",
      "1     2020-02-13     AL     0        0      0    0.0   1.0\n",
      "2     2020-02-13     AR     0        0      0    0.0   1.0\n",
      "3     2020-02-13     AZ     0        0      0    0.0   1.0\n",
      "4     2020-02-13     CA     0        0      0    0.0   1.0\n",
      "\n",
      "INFO:__main__:\n",
      "      datetimeobject STUSPS    range midpoint   median       score  rank\n",
      "14351     2020-11-14     WY  98.3789  62.5753  65.5172  287.147018   1.0\n",
      "14326     2020-11-14     MT  73.3712  45.5839  36.7021  195.807095   2.0\n",
      "14342     2020-11-14     SD  64.9144   41.981  42.1053  175.189650   3.0\n",
      "14328     2020-11-14     ND  62.1433  34.1458     42.5  141.002968   4.0\n",
      "14349     2020-11-14     WI  49.8947  29.4495  29.8104  115.144948   5.0\n",
      "\n",
      "INFO:__main__:\n",
      "hospitalizedRateDelta\n",
      "\n",
      "INFO:__main__:\n",
      "  datetimeobject STUSPS range midpoint median  score  rank\n",
      "0     2020-02-13     AK     0        0      0    0.0   1.0\n",
      "1     2020-02-13     AL     0        0      0    0.0   1.0\n",
      "2     2020-02-13     AR     0        0      0    0.0   1.0\n",
      "3     2020-02-13     AZ     0        0      0    0.0   1.0\n",
      "4     2020-02-13     CA     0        0      0    0.0   1.0\n",
      "\n",
      "INFO:__main__:\n",
      "      datetimeobject STUSPS    range midpoint   median       score  rank\n",
      "14326     2020-11-14     MT  42.0186  53.5206   50.479  200.066096   1.0\n",
      "14328     2020-11-14     ND  51.7051  29.2627  31.7625  115.457740   2.0\n",
      "14342     2020-11-14     SD   49.885  29.0815  32.2308  113.700366   3.0\n",
      "14351     2020-11-14     WY  44.0165  25.9509  31.2217   98.212943   4.0\n",
      "14349     2020-11-14     WI  38.4174  22.5128  23.7366   82.138018   5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for section in sections:\n",
    "    \n",
    "    # A dta set w.r.t. a measure\n",
    "    example = percentages[['datetimeobject', 'STUSPS', 'period', section]]\n",
    "    logger.info('\\n{}\\n'.format(section))\n",
    "    \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median'] \n",
    "    data = baseline(data=example, section=section)\n",
    "        \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median', 'score']\n",
    "    data = scores(data=data)\n",
    "            \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median', 'score', 'rank']\n",
    "    ranks = data[['datetimeobject', 'score']].groupby(by='datetimeobject').rank(method='min', ascending=False).score\n",
    "    data = pd.concat([data, ranks.rename('rank')], axis=1)    \n",
    "    data.to_csv(path_or_buf=os.path.join(warehouse, section + 'Dispersion.csv'), header=True, encoding='utf-8', index=False)\n",
    "    logger.info('\\n{}\\n'.format(data.head()))\n",
    "    \n",
    "    # ['datetimeobject', 'STUSPS', 'range', 'midpoint', 'median', 'score', 'rank']\n",
    "    inbrief = latest(data=data)\n",
    "    inbrief.to_csv(path_or_buf=os.path.join(warehouse, section + 'DispersionLatest.csv'), header=True, encoding='utf-8', index=False)\n",
    "    logger.info('\\n{}\\n'.format(inbrief.head()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
